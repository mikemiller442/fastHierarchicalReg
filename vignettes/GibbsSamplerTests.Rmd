---
title: "HW3"
author: "Michael Miller"
date: "2022-11-06"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

### Load Libraries

```{r}
library(bench)
library(devtools)

devtools::install_github("mikemiller442/fastHierarchicalReg")
devtools::install_github("kangjian2016/fastBayesReg")

library(fastHierarchicalReg)
library(fastBayesReg)
```

### Simulate Data 1

```{r}
n <- 10000
numBeta <- 100
betaSD <- 0.75
XSD <- 0.5
errorSD <- 2.0
e <- rnorm(n, mean = 0, sd = errorSD)
beta <- rnorm(numBeta, mean = 0, sd = betaSD*errorSD)
Z <- matrix(NA, nrow = n, ncol = numBeta)
for (i in 1:ncol(Z)) {
  Z[,i] <- rnorm(n, mean = 0, sd = XSD)
}

y <- Z %*% beta + e
output <- y - mean(y)
```

### Run Gibbs Sampler

```{r}
X <- Z
testX <- Z
resp <- output
testResp <- output

numEpochs <- 10000
numDiscard <- 2000
numChains <- 4
numCores <- 8
lambdaSqPrior <- 1.0
regVarPrior <- 1.0

res <- fastHierarchicalReg::linRegGibbsProcessed(X = X,
                                                 testX = testX,
                                                 Y = output,
                                                 testY = output,
                                                 lambdaSqPrior = lambdaSqPrior,
                                                 regVarPrior = regVarPrior,
                                                 numEpochs = numEpochs,
                                                 numDiscard = numDiscard,
                                                 numChains = numChains,
                                                 numCores = numCores)
```

### Compare means between model output to true values

```{r}
# Comparing beta
paramBeta <- as.numeric(res$postMeanList$beta)
all.equal(beta,paramBeta)

# Comparing lambda
paramLambda <- sqrt(as.numeric(res$postMeanList$lambdaSq))
all.equal(betaSD,paramLambda)

# Comparing sigma
paramSigma <- sqrt(as.numeric(res$postMeanList$regVar))
all.equal(errorSD,paramSigma)
```

### Rhat Convergence Diagnostic - Check Convergence to 1.0

```{r}
all.equal(as.numeric(unlist(res$RhatList)),rep(1.0,length(unlist(res$RhatList))))
```

### Simulate Data 2

```{r}
n <- 10000
numBeta <- 5
betaSD <- 0.75
XSD <- 0.5
errorSD <- 2.0
e <- rnorm(n, mean = 0, sd = errorSD)
beta <- rnorm(numBeta, mean = 0, sd = betaSD*errorSD)
Z <- matrix(NA, nrow = n, ncol = numBeta)
for (i in 1:ncol(Z)) {
  Z[,i] <- rnorm(n, mean = 0, sd = XSD)
}

y <- Z %*% beta + e
output <- y - mean(y)
```

### Run Gibbs Sampler For Methods Packages

```{r}
X <- Z
testX <- Z
resp <- output
testResp <- output

numEpochs <- 4000
numDiscard <- 2000
numChains <- 4
lambdaSqPrior <- 1.0
regVarPrior <- 1.0

res <- fastHierarchicalReg::linRegGibbsProcessed(X = X,
                                                 testX = testX,
                                                 Y = output,
                                                 testY = output,
                                                 lambdaSqPrior = lambdaSqPrior,
                                                 regVarPrior = regVarPrior,
                                                 numEpochs = numEpochs,
                                                 numDiscard = numDiscard,
                                                 numChains = numChains,
                                                 numCores = numCores)

numEpochs <- 10000
numDiscard <- 2000

resKJ <- fastBayesReg::fast_normal_lm(y = y,
                                      X = X,
                                      mcmc_sample = numEpochs,
                                      burnin = numDiscard,
                                      a_sigma = 0.1,
                                      b_sigma = 0.1)
```

### Compare regression coefficient posterior means between model output and Stan

```{r}
# Comparing posterior means
kjBeta <- as.numeric(resKJ$post_mean$betacoef)
paramBeta <- as.numeric(res$postMeanList$beta)
all.equal(kjBeta,paramBeta)
```

### Benchmark High Dimensional Example

```{r}
n <- 5000
numBeta <- 500
betaSD <- 0.05
XSD <- 0.5
errorSD <- 2.0
e <- rnorm(n, mean = 0, sd = errorSD)
beta <- rnorm(numBeta, mean = 0, sd = betaSD*errorSD)
Z <- matrix(NA, nrow = n, ncol = numBeta)
for (i in 1:ncol(Z)) {
  Z[,i] <- rnorm(n, mean = 0, sd = XSD)
}

y <- Z %*% beta + e
output <- y - mean(y)

funMod <- function() {
  X <- Z
  testX <- Z
  resp <- output
  testResp <- output
  
  numEpochs <- 4000
  numDiscard <- 2000
  lambdaSqPrior <- 1.0
  regVarPrior <- 1.0
  
  res <- fastHierarchicalReg::linRegGibbs(X = X,
                                          testX = testX,
                                          Y = resp,
                                          testY = testResp,
                                          numEpochs = numEpochs,
                                          regVarPrior = regVarPrior,
                                          lambdaSqPrior = lambdaSqPrior)
  postBeta <- res$coefBeta[,(numDiscard+2):(numEpochs+1)]
  paramBeta <- rowMeans(postBeta)
  return(paramBeta)
}

funKJ <- function() {
  numEpochs <- 4000
  numDiscard <- 2000
  resKJ <- fastBayesReg::fast_normal_lm(y = y,
                                        X = X,
                                        mcmc_sample = numEpochs,
                                        burnin = numDiscard,
                                        a_sigma = 0.1,
                                        b_sigma = 0.1)
  kjBeta <- as.numeric(mean(model1[,1]))
  return(kjBeta)
}

benchMarkRes <- bench::mark(funMod(),
                            funKJ(),
                            iterations = 2,
                            check = FALSE)
benchMarkTable <- benchMarkRes[c("expression", "min", "median","mem_alloc","n_gc")]
knitr::kable(benchMarkTable)
```















